{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "nlp assignment 2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNXNjybLakkW",
        "outputId": "e5a040a0-a24c-4a7b-9083-329a154b1cdf"
      },
      "source": [
        "print(\"Importing libraries ... \", end=\"\")\n",
        "from collections import Counter\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "import datetime\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "print(\"done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Importing libraries ... done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U4fqr3IWD2_",
        "outputId": "194c120e-a192-47b7-d08e-6f34f5ef354d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZMIs2ufWGdG"
      },
      "source": [
        "with open('/content/drive/My Drive/datasets/brown.txt', 'r') as f: \n",
        "    data = f.read()\n",
        "data = data.split('.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZrXxQQgYCUa"
      },
      "source": [
        "import re\n",
        "def clean(string):\n",
        "    string = string.encode('ascii', 'ignore').decode('ascii')\n",
        "    string = re.sub('^\\[.*\\]','',string)\n",
        "    string = re.sub('^.*:','',string)\n",
        "    string = string.strip()\n",
        "    string = string.strip('\\\"')\n",
        "    string = re.sub('\\?+','?',string)\n",
        "    string = re.sub('!+','!',string)\n",
        "    string = re.sub('\\.+','.',string)\n",
        "    string = re.sub(' +',' ',string)\n",
        "    string = re.sub('\\(.*\\)','',string)\n",
        "    string = string.replace(':)','')\n",
        "    string = string.replace(';)','')\n",
        "    string = string.replace('*','')\n",
        "    string = string.strip()\n",
        "    return string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnlFP6xoWIrO"
      },
      "source": [
        "for i in range(len(data)):\n",
        "  data[i] = data[i].replace('\\n',' ')\n",
        "  data[i] = clean(data[i])\n",
        "  data[i] = data[i] + '.'\n",
        "cleaned = []\n",
        "for i in range(len(data)):\n",
        "  if len(data[i])>=10:\n",
        "    cleaned.append(data[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu_933VwGn-n",
        "outputId": "4f7fbb9e-68f1-47a2-e8eb-193ec44dadd1"
      },
      "source": [
        "len(cleaned)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48920"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8tE1tjaGqa3"
      },
      "source": [
        "# from random import shuffle\n",
        "# shuffle(data)\n",
        "train_data = cleaned[:20000]\n",
        "test_data = cleaned[20000:40000]\n",
        "validation_data = cleaned[40000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0kqCeMra-lb",
        "outputId": "553ee08a-6de3-44a7-8424-79ab6ff1c0c7"
      },
      "source": [
        "print(\"Initialising Hyperparameters ... \", end=\"\")\n",
        "\n",
        "EMBEDDING_DIM = 256\n",
        "\n",
        "SEQUENCE_LENGTH = 2\n",
        "\n",
        "EPOCHS = 2\n",
        "BATCH_SIZE = 64\n",
        "LR = 3e-3\n",
        "\n",
        "PADDING_IDX = 0\n",
        "LSTM_CELLS = 192\n",
        "VANILLA_CELLS = 96\n",
        "LSTM_LAYERS = 2\n",
        "LSTM_DROPOUT = 0.4\n",
        "BI_LSTM = False\n",
        "\n",
        "PREDICTION_SIZE = 20\n",
        "\n",
        "print(\"done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialising Hyperparameters ... done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yle-z4PBqP1x",
        "outputId": "5dd3c101-d646-4eb2-eb3a-00272267b528"
      },
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', DEVICE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5nZVTcJLO1W",
        "outputId": "194658c5-2136-49bf-ad50-b3743b8ab862"
      },
      "source": [
        "print(\"cudnn enabled:\", torch.backends.cudnn.enabled)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cudnn enabled: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4S4AsNt7LlE_",
        "outputId": "5c1b2bb4-56f3-4c6a-9880-a21ee8026f7b"
      },
      "source": [
        "print(\"GPU Name: \",torch.cuda.get_device_name(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU Name:  Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrc6ooPUS1Tw"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, seq_len):\n",
        "\n",
        "        # length of sequence in consideration\n",
        "        self.seq_len = seq_len\n",
        "        # a list of all the tokens\n",
        "        self.words = self.load_words()\n",
        "        # a sorted list of all the tokens\n",
        "        self.uniq_words = self.get_uniq_words()\n",
        "        # storing the vocublary size\n",
        "        self.vocab_size = len(self.uniq_words)\n",
        "\n",
        "        # dictionaries to convert to and from words\n",
        "        # used for embeddings and the generated text \n",
        "        # Note the index+1 0 is kept for padding \n",
        "        self.index_to_word = {\n",
        "            index: word for index, word in enumerate(self.uniq_words)\n",
        "        }\n",
        "        self.word_to_index = {\n",
        "            word: index for index, word in enumerate(self.uniq_words)\n",
        "        }\n",
        "\n",
        "        # a grand sequence of the words, each translated \n",
        "        # into its respective indices\n",
        "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
        "\n",
        "\n",
        "    def load_words(self):\n",
        "        text = ' '.join(train_data)\n",
        "        return text_to_word_sequence(text) \n",
        "\n",
        "    def get_uniq_words(self):\n",
        "        word_counts = Counter(self.words)\n",
        "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "\n",
        "    # returns length of the dataset. required by torch\n",
        "    def __len__(self):\n",
        "        return len(self.words_indexes) - self.seq_len\n",
        "\n",
        "    # returns an item, as if accessed from the dictionary as\n",
        "    # dataset[i]. required by torch\n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "            torch.tensor(self.words_indexes[index:index+self.seq_len]),\n",
        "            torch.tensor(self.words_indexes[index+1:index+self.seq_len+1]),\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZlqqJE3cGVQ"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            vocab_size,\n",
        "            embedding_dim,\n",
        "            lstm_cells,\n",
        "            lstm_layers,\n",
        "            lstm_dropout,\n",
        "            is_bidirectional,\n",
        "            vanilla_cells,\n",
        "            seq_len,\n",
        "            batch_size\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.lstm_cells = lstm_cells\n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.lstm_dropout = lstm_dropout\n",
        "        self.is_bidirectional = is_bidirectional\n",
        "        self.vanilla_cells = vanilla_cells\n",
        "        self.seq_len = seq_len\n",
        "        self.num_directions = 2 if is_bidirectional else 1\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=lstm_cells,\n",
        "            num_layers=lstm_layers,\n",
        "            dropout=lstm_dropout,\n",
        "            bidirectional=is_bidirectional\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(\n",
        "            lstm_cells*self.num_directions,\n",
        "            vanilla_cells\n",
        "        )\n",
        "\n",
        "        self.fc2 = nn.Linear(\n",
        "            vanilla_cells,\n",
        "            vocab_size\n",
        "        )\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        embed_output = self.embedding(x)\n",
        "        lstm_output, new_state = self.lstm(embed_output, prev_state)\n",
        "        fc1_output = self.fc1(lstm_output)\n",
        "        fc2_output = self.fc2(fc1_output)\n",
        "\n",
        "        return fc2_output, new_state\n",
        "\n",
        "    def init_lstm(self):\n",
        "        return (\n",
        "            torch.zeros(\n",
        "                self.lstm_layers*self.num_directions, \n",
        "                self.seq_len,\n",
        "                self.lstm_cells\n",
        "            ),\n",
        "            torch.zeros(\n",
        "                self.lstm_layers*self.num_directions, \n",
        "                self.seq_len,\n",
        "                self.lstm_cells\n",
        "            )\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-XMZq6GmKPf",
        "outputId": "9358964a-ff9d-44ef-e112-aa18e848b027"
      },
      "source": [
        "print(\"Processing Dataset ... \", end=\"\")\n",
        "dataset = Dataset(SEQUENCE_LENGTH)\n",
        "VOCAB_SIZE = dataset.vocab_size\n",
        "print(\"done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing Dataset ... done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ8AxD09fjBr",
        "outputId": "0aa53cdc-1f7a-432c-a5e5-ae5a108d9f69"
      },
      "source": [
        "print(\"Creating Model ... \", end=\"\")\n",
        "model = Model(\n",
        "    VOCAB_SIZE,\n",
        "    EMBEDDING_DIM,\n",
        "    LSTM_CELLS,\n",
        "    LSTM_LAYERS,\n",
        "    LSTM_DROPOUT,\n",
        "    BI_LSTM,\n",
        "    VANILLA_CELLS,\n",
        "    SEQUENCE_LENGTH,\n",
        "    BATCH_SIZE\n",
        ")\n",
        "print(\"done.\")\n",
        "print(\"=\"*80)\n",
        "print(\"MODEL:\")\n",
        "print(model)\n",
        "print(\"=\"*80)\n",
        "print(\"Shifting model to the GPU ... \", end=\"\")\n",
        "model.to(DEVICE)\n",
        "print(\"done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating Model ... done.\n",
            "================================================================================\n",
            "MODEL:\n",
            "Model(\n",
            "  (embedding): Embedding(30080, 256)\n",
            "  (lstm): LSTM(256, 192, num_layers=2, dropout=0.4)\n",
            "  (fc1): Linear(in_features=192, out_features=96, bias=True)\n",
            "  (fc2): Linear(in_features=96, out_features=30080, bias=True)\n",
            ")\n",
            "================================================================================\n",
            "Shifting model to the GPU ... done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5h5U4o64-XZ",
        "outputId": "54b2894a-4a52-4f18-a5f1-c34586fab511"
      },
      "source": [
        "print(\"Setting up loss and optimizers ... \", end=\"\")\n",
        "\n",
        "CRITERION = nn.CrossEntropyLoss()\n",
        "OPTIMIZER = optim.Adam(model.parameters(), lr=LR)\n",
        "print(\"done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting up loss and optimizers ... done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALNAE-jtp2Fr"
      },
      "source": [
        "def train(dataset, model):\n",
        "    # getting the model ready for training ...\n",
        "    model.train()\n",
        "    # preparing the data to be iterated over\n",
        "    data_generator = DataLoader(dataset, batch_size=BATCH_SIZE, drop_last=True)\n",
        "    \n",
        "    # stores losses for all the epochs\n",
        "    loss_values = []\n",
        "    # stores a list of the epoch number\n",
        "    epoch_numbers = []\n",
        "    \n",
        "    # going over all the epochs\n",
        "    for epoch in range(EPOCHS):\n",
        "        # initialising the model for each epoch\n",
        "        h_state, c_state = model.init_lstm()\n",
        "        \n",
        "        # sending the inits to the GPU\n",
        "        h_state, c_state = h_state.to(DEVICE), c_state.to(DEVICE)\n",
        "\n",
        "        # iterating over the dataset\n",
        "        for batch, (x, y) in enumerate(tqdm(data_generator)):\n",
        "            # transferring data to the GPU\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            \n",
        "            # resetting the gradients for each batch \n",
        "            # for proper training\n",
        "            OPTIMIZER.zero_grad()\n",
        "\n",
        "            # predictions from the model\n",
        "            y_pred, (h_state, c_state) = model(x, (h_state, c_state))\n",
        "\n",
        "            loss = CRITERION(y_pred.transpose(1, 2), y)\n",
        "            h_state = h_state.detach()\n",
        "            c_state = c_state.detach()\n",
        "            loss.backward()\n",
        "            OPTIMIZER.step()\n",
        "\n",
        "        loss_values.append(loss.item())\n",
        "        epoch_numbers.append(epoch+1)\n",
        "        print(f\"Epoch: {epoch}, loss: {loss.item()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZRUPHvwYrER",
        "outputId": "029b5572-650d-4e8e-9a9b-22a2b522f252"
      },
      "source": [
        "train(dataset, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6828/6828 [04:13<00:00, 26.92it/s]\n",
            "  0%|          | 4/6828 [00:00<03:30, 32.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, loss: 7.682465076446533\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6828/6828 [04:13<00:00, 26.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, loss: 6.959965705871582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhyzTp8IZLOa",
        "outputId": "d4a68882-04d9-46ab-bf3b-ceace49f7938"
      },
      "source": [
        "perplexity  = torch.exp(torch.Tensor([5.690529823303223]))\n",
        "print(perplexity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([296.0504])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOOp-UNsMPu8"
      },
      "source": [
        "x = datetime.datetime.now()\n",
        "current_time = str(x.year)+\"-\"+str(x.month)+\"-\"+str(x.day)+\"-\"+str(x.hour)+\"-\"+str(x.minute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEYDu4iLFGr-"
      },
      "source": [
        "torch.save(model.state_dict(), f'{current_time}.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9R3pYSFM_Ma"
      },
      "source": [
        "HYPERPARAMETERS = {\n",
        "    \"EMBEDDING_DIM\": EMBEDDING_DIM,\n",
        "    \n",
        "    \"SEQUENCE_LENGTH\": SEQUENCE_LENGTH,\n",
        "\n",
        "    \"EPOCHS\": EPOCHS,\n",
        "    \"BATCH_SIZE\": BATCH_SIZE,\n",
        "    \"LR\": LR,\n",
        "\n",
        "    \"LSTM_CELLS\": LSTM_CELLS,\n",
        "    \"VANILLA_CELLS\": VANILLA_CELLS,\n",
        "    \"LSTM_LAYERS\": LSTM_LAYERS,\n",
        "    \"LSTM_DROPOUT\": LSTM_DROPOUT,\n",
        "    \"BI_LSTM\": BI_LSTM,\n",
        "\n",
        "    \"PREDICTION_SIZE\": PREDICTION_SIZE,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvEAOj8fN3EO"
      },
      "source": [
        "with open(f'{current_time}.json', 'w+') as fp:\n",
        "    json.dump(HYPERPARAMETERS, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnEFDpKvvSrM",
        "outputId": "6124c551-9fb3-4802-a38c-d0a50472b850"
      },
      "source": [
        "# shifting model back to the CPU\n",
        "model.to('cpu')\n",
        "# getting the model ready for testing ...\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (embedding): Embedding(30080, 256)\n",
              "  (lstm): LSTM(256, 192, num_layers=2, dropout=0.4)\n",
              "  (fc1): Linear(in_features=192, out_features=96, bias=True)\n",
              "  (fc2): Linear(in_features=96, out_features=30080, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWUIDzcGq_U8"
      },
      "source": [
        "def generate(dataset, model, seed):\n",
        "    # # shifting model back to the CPU\n",
        "    # model.to('cpu')\n",
        "    # # getting the model ready for testing ...\n",
        "    # model.eval()\n",
        "    # a list of words\n",
        "    words = text_to_word_sequence(seed)\n",
        "    # # initialising the model parameters    \n",
        "    h_state, c_state = model.init_lstm()\n",
        "    # going over, and predicting\n",
        "    x = torch.tensor([[dataset.word_to_index[w] for w in words[-2:]]])\n",
        "    \n",
        "    y_pred, (h_state, c_state) = model(x, (h_state, c_state))\n",
        "    loss = CRITERION(y_pred.transpose(1, 2), x)\n",
        "    perplexity  = torch.exp(torch.Tensor([loss.item()]))\n",
        "    perp = int(perplexity[0])\n",
        "    #print(perp)\n",
        "    return perp/len(words)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kCQTuRpVjaL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b87c3684-0718-4a00-a6f1-ccf8011e3d35"
      },
      "source": [
        "seeds = test_data\n",
        "lm = []\n",
        "lines = []\n",
        "tot, num = 0, 0\n",
        "for i in range(len(seeds)):\n",
        "    # seed_list = seeds[i].split()\n",
        "    # seed = \"\"\n",
        "    # for word in seed_list:\n",
        "    #     seed += word +\" \"\n",
        "    # seed = seed[:-1]\n",
        "    if i%3000==0:\n",
        "      print(i)\n",
        "    try:\n",
        "      perplexity = generate(dataset, model, seed=seeds[i])\n",
        "      tot += perplexity\n",
        "      num += 1\n",
        "      sent = f'{seeds[i]}\\t{perplexity}'\n",
        "      lines.append(sent)\n",
        "      \n",
        "      \n",
        "    except:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "3000\n",
            "6000\n",
            "9000\n",
            "12000\n",
            "15000\n",
            "18000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAv_OQhZu7Tg",
        "outputId": "9209e878-2fa6-442a-9977-68eda9862681"
      },
      "source": [
        "lines[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Lloyd Lewis wrote that when he first knew Carl in 1916, Sandburg was making $27.\\t491.3333333333333',\n",
              " '50 a week writing features for the <Day Book> and eating sparse luncheons in one-arm restaurants.\\t3203.1176470588234',\n",
              " 'He walked home at night for two miles beyond the end of a suburban trolley.\\t6438.8',\n",
              " 'When fame came it changed Sandburg only slightly.\\t341.125',\n",
              " 'I know a starving man who is fed never remembers all the pangs of his starvation, I know that.\\t133.1578947368421']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLhUWuLAltV2"
      },
      "source": [
        "with open('testing_lstm.txt', 'w') as f:\n",
        "    for item in lines:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKDnTvl-DXLg",
        "outputId": "df872b91-0401-4d1d-9899-00321d5e9a3c"
      },
      "source": [
        "num"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17037"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSA36aYOrWxc",
        "outputId": "a4ac2dd8-4a12-4ae4-cdee-96f343d59f5d"
      },
      "source": [
        "tot/num"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5827.078014557231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbUQrweksMsh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}